- Include a link to the original paper in your reference list.


# Attention Is All You Need  


Ashish Vaswani<sup>1</sup> Google Brain avaswani@google.com  


Noam Shazeer<sup>2</sup> Google Brain noash@gmail.com  


Niki Parmar<sup>3</sup> Google Research nikitp@google.com  


Jakob Uszkoreit<sup>4</sup> Google Research usz@goolge.com  


Lilou Jones<sup>5</sup> Google Research lilou@google.com  


Aidan N. Gomez<sup>1</sup> University of Toronto aidan@cs.toronto.edu  


Lukasz Kaiser<sup>6</sup> Google Brain lukaszalaskier@google.com  


## Illia Polosukhin<sup>7</sup>  


illia.polosukhinsgmail.com  


## Abstract  


The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolution layers altogether. Our model is trained end-to-end using only unlabeled text as supervision to acquire multi- billion word parallelizable and requiring significantly less time to train. Our model achieves \(28.8 \mathrm{BLEU}\) on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single- model state-of-the-art BLEU score of 41.0 after training for 9.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.  


## Introduction  


Recurrent neural networks, long short- term memory [2] and gated recurrent [3] neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation [20][23]. Numerous efforts have since continued to push the boundaries of recurrent language models and encoder- decoder architectures [10][11][13].
