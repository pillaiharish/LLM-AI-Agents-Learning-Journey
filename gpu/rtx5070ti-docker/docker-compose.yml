version: '3.8'

services:
  ml-env:
    build:
      context: .
      dockerfile: Dockerfile
    image: ml-gpu-env:latest
    container_name: ml-workspace

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    volumes:
      - ./workspace:/workspace
      - ./data:/data
      - ./models:/models

    stdin_open: true
    tty: true
    shm_size: '8gb'
    network_mode: host

    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_LAUNCH_BLOCKING=1
      - TORCH_CUDA_ARCH_LIST=5.0;6.0;7.0;7.5;8.0;8.6;9.0;12.0
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

    restart: unless-stopped
    command: sleep infinity
